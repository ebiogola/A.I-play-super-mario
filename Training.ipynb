{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d63118",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f9b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym \n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, RIGHT_ONLY \n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gym_utils import SMBRamWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf3dac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec773972",
   "metadata": {},
   "source": [
    "# 2. Process Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecdffe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cropping size\n",
    "x0 = 0\n",
    "x1 = 16\n",
    "y0 = 0\n",
    "y1 = 13\n",
    "n_stack = 4\n",
    "n_skip = 4\n",
    "\n",
    "env_wrap = SMBRamWrapper(env, [x0, x1, y0, y1], n_stack=n_stack, n_skip=n_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1018d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test env_wrap\n",
    "done = True\n",
    "for i in range(150):\n",
    "    if done:\n",
    "        state = env_wrap.reset()\n",
    "    state, reward, done, info = env_wrap.step(env_wrap.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be737c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 16, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "503a7d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, n_stack, figsize=(14,10))\n",
    "for i in range(n_stack):\n",
    "    ax[i].imshow(state[:,:,n_stack-i-1], vmin=-1, vmax=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc903d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply other wrapper functions\n",
    "env_wrap = Monitor(env_wrap)  # for tensorboard log\n",
    "env_wrap = DummyVecEnv([lambda: env_wrap])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4a86f",
   "metadata": {},
   "source": [
    "# 3. Setup RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09f25b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "# Save intermediate models\n",
    "# Copied from Nicholas Renotte's code\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, \n",
    "                 starting_steps=0, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.starting_steps = starting_steps\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls + int(self.starting_steps)))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "# Linear learning rate schedule\n",
    "# https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#learning-rate-schedule\n",
    "from typing import Callable\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d20a1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFY THESE TWO DIRECTORIES BEFORE TRAINING A NEW MODEL ###\n",
    "MODEL_DIR = './models/NEW_MODEL_DIR'\n",
    "LOG_DIR = './logs/NEW_LOG_DIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b9d9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env_wrap, verbose=1, learning_rate=linear_schedule(3e-4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f2b67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1e5, starting_steps=0, save_path=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212fb30",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd9b8e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m t_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10e6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m t_elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n",
      "File \u001b[1;32mc:\\Users\\ebiog\\OneDrive\\Documents\\Master projects\\A.I. Plays Super Mario Game\\Resources\\env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:304\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    293\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    302\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPPO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ebiog\\OneDrive\\Documents\\Master projects\\A.I. Plays Super Mario Game\\Resources\\env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:242\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    230\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    239\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnPolicyAlgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    240\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 242\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n",
      "File \u001b[1;32mc:\\Users\\ebiog\\OneDrive\\Documents\\Master projects\\A.I. Plays Super Mario Game\\Resources\\env\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:445\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, eval_env, callback, eval_freq, n_eval_episodes, log_path, reset_num_timesteps, tb_log_name)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mconfigure_logger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensorboard_log, tb_log_name, reset_num_timesteps)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Create eval callback if needed\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_timesteps, callback\n",
      "File \u001b[1;32mc:\\Users\\ebiog\\OneDrive\\Documents\\Master projects\\A.I. Plays Super Mario Game\\Resources\\env\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:381\u001b[0m, in \u001b[0;36mBaseAlgorithm._init_callback\u001b[1;34m(self, callback, eval_env, eval_freq, n_eval_episodes, log_path)\u001b[0m\n\u001b[0;32m    372\u001b[0m     eval_callback \u001b[38;5;241m=\u001b[39m EvalCallback(\n\u001b[0;32m    373\u001b[0m         eval_env,\n\u001b[0;32m    374\u001b[0m         best_model_save_path\u001b[38;5;241m=\u001b[39mlog_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m         n_eval_episodes\u001b[38;5;241m=\u001b[39mn_eval_episodes,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    379\u001b[0m     callback \u001b[38;5;241m=\u001b[39m CallbackList([callback, eval_callback])\n\u001b[1;32m--> 381\u001b[0m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m callback\n",
      "File \u001b[1;32mc:\\Users\\ebiog\\OneDrive\\Documents\\Master projects\\A.I. Plays Super Mario Game\\Resources\\env\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:48\u001b[0m, in \u001b[0;36mBaseCallback.init_callback\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_env \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_env()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlogger\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m, in \u001b[0;36mTrainAndLoggingCallback._init_callback\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "model.learn(total_timesteps=10e6, callback=callback)\n",
    "\n",
    "t_elapsed = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Wall time: {} s'.format(round(t_elapsed, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be236c1b",
   "metadata": {},
   "source": [
    "# Save and load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ef893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = os.path.join(MODEL_DIR, 'SAVED_MODEL_NAME')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd36cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "MODEL_DIR = './models/SAVED_MODEL_NAME'\n",
    "LOG_DIR = './logs/SAVED_LOG_DIR'\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, 'SAVED_MODEL_NAME')\n",
    "model = PPO.load(model_path, env=env_wrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d11ab",
   "metadata": {},
   "source": [
    "# Open tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b606aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_NAME = 'PPO_5'\n",
    "TB_LOG = os.path.join(LOG_DIR, LOG_NAME)\n",
    "\n",
    "!tensorboard --logdir={TB_LOG}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f39a6",
   "metadata": {},
   "source": [
    "# 4. Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env_wrap, n_eval_episodes=1, deterministic=True, render=False, return_episode_rewards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 1\n",
    "\n",
    "for episode in range(1, episode+1):\n",
    "    states = env_wrap.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env_wrap.render()\n",
    "        action, _ = model.predict(states, deterministic=True)\n",
    "        states, reward, done, info = env_wrap.step(action)\n",
    "        score += reward\n",
    "        time.sleep(0.01)\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "#env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
